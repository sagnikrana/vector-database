{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.utils import embedding_functions\n",
    "load_dotenv()\n",
    "openai_client = OpenAI(api_key=os.getenv('OPEN_AI_API_KEY'))\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_path = '../data/text-files'\n",
    "\n",
    "def split_text(text, chunk_size=1000, chunk_overlap=20):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - chunk_overlap\n",
    "    return chunks\n",
    "\n",
    "def load_documents_from_directory(directory_path):\n",
    "    print(\"==== Loading documents from directory ====\")\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(\n",
    "                os.path.join(directory_path, filename), \"r\", encoding=\"utf-8\"\n",
    "            ) as file:\n",
    "                documents.append({\"id\": filename, \"text\": file.read()})\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the client\n",
    "chroma_client = chromadb.PersistentClient('../data/chroma_persist.db')\n",
    "collection_name = 'test_collection'\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "collection = chroma_client.get_or_create_collection(collection_name, embedding_function=default_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Loading documents from directory ====\n",
      "Loaded: 21 documents\n",
      "==== Splitting docs into chunks ====\n"
     ]
    }
   ],
   "source": [
    "# Loading the txt files from the document into the chroma db\n",
    "documents = load_documents_from_directory(text_file_path)\n",
    "print(f'Loaded: {len(documents)} documents')\n",
    "\n",
    "# Split the documents into chunks\n",
    "chunked_documents = []\n",
    "print(\"==== Splitting docs into chunks ====\")\n",
    "for doc in documents:\n",
    "    chunks = split_text(doc[\"text\"])\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunked_documents.append({\"id\": f\"{doc['id']}_chunk{i+1}\", \"text\": chunk})\n",
    "\n",
    "# Generate embeddings for the document chunks\n",
    "for doc in chunked_documents:\n",
    "    print(\"==== Generating embeddings... ====\")\n",
    "    doc[\"embedding\"] = get_openai_embedding(doc[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt', 'text': 'Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”\\n\\nPando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based freight tech marketplace — and their first startup. The two saw firsthand manufacturers, distributors and retailers were struggling with legacy tech and point solutions to understand, optimize and manage their global logistics operations — or at least, that’s the story Jayakrishnan tells.\\n\\n“Supply chain leaders were trying to build their own tech and throwing people at the problem,” he said. “This caught our attention — we spent months talking to and building for enterprise users at warehouses, factories, freight yards and ports and eventually, in 2018, decided to start Pando to solve for global logistics through a software-as-a-service platform offering.”\\n\\nThere’s truth to what Jayakrishnan’s expressing about pent-up demand. According to a recent McKinsey survey, supply chain companies had — and have — a strong desire for tools that deliver greater supply chain visibility. Sixty-seven percent of respondents to the survey say that they’ve implemented dashboards for this purpose, while over half say that they’re investing in supply chain visibility services more broadly.\\n\\nPando aims to meet the need by consolidating supply chain data that resides in multiple silos within and outside of the enterprise, including data on customers, suppliers, logistics service providers, facilities and product SKUs. The platform provides various tools and apps for accomplishing different tasks across freight procurement, trade and transport management, freight audit and payment and document management, as well as dispatch planning and analytics.\\n\\nCustomers can customize the tools and apps or build their own using Pando’s APIs. This, along with the platform’s emphasis on no-code capabilities, differentiates Pando from incumbents like SAP, Oracle, Blue Yonder and E2Open, Jayakrishnan asserts.\\n\\n“Pando comes pre-integrated with leading enterprise resource planning (ERPs) systems and has ready APIs and a professional services team to integrate with any new ERPs and enterprise systems,” he added. “Pando’s no-code capabilities enable business users to customize the apps while maintaining platform integrity — reducing the need for IT resources for each customization.”\\n\\nPando also taps algorithms and forms of machine learning to make predictions around supply chain events. For example, the platform attempts to match customer orders with suppliers, customers through the “right” channel (in terms of aspects like cost and carbon footprint) and fulfillment strategy (e.g. mode of freight, carrier, etc.). Beyond this, Pando can detect anomalies among deliveries, orders and freight invoices and anticipate supply chain risk given demand and supply trends.\\n\\nPando isn’t the only vendor doing this. Altana, which bagged $100 million in venture capital last October, uses an AI system to connect to and learn from logistics and business-to-business data — creating a shared view of supply chain networks. Everstream, another Pando rival, offers its own dashboards for data analysis, integrated with existing ERP, transportation management and supplier relationship management systems.\\n\\nBut Pando has a compelling sales pitch, judging by its momentum. The company counts Fortune 500 manufacturers and retailers — including P&G, J&J, Valvoline, Castrol, Cummins, Siemens, Danaher and Accuride — among its customer base. Since the startup’s Series A in 2020, revenue has grown 8x while the number of customers has increased 5x, Jayakrishnan said.\\n\\nAsked whether he expects expansion to continue well into the future, given the signs of potential trouble on the horizon, Jayakrishnan seemed fairly optimistic. He pointed to a Deloitte survey that found that more than 70% of manufacturing companies have been impacted by supply chain disruptions in the past year, with 90% of those companies experiencing increased costs and declining productivity.\\n\\nThe result of those major disruptions? The digital logistics market is estimated to climb to $46.5 billion by 2025, per Markets and Markets — up from $17.4 billion in 2019. Crunchbase reports that investors poured more than $7 billion in seed through growth-stage rounds globally for supply chain-focused startups from January to October 2022, nearly eclipsing 2021’s record-setting levels.\\n\\n“Pando has a strong balance sheet and profit and loss statement, with an eye on profitable growth,” Jayakrishnan said. “We’re are scaling operations in North America, Europe and India with marquee customer wins and a network of strong partners … Pando is well-positioned to ride this growth wave, and drive supply chain agility for the 2030 economy.”'}\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(doc)\n",
    "    doc[]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Inserting chunks into db;;; ====\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunked_documents:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==== Inserting chunks into db;;; ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m----> 5\u001b[0m         ids\u001b[38;5;241m=\u001b[39m[doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]], documents\u001b[38;5;241m=\u001b[39m[doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]], embeddings\u001b[38;5;241m=\u001b[39m[doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      6\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'embedding'"
     ]
    }
   ],
   "source": [
    "# Load the chunked documents into the database\n",
    "for doc in chunked_documents:\n",
    "    print(\"==== Inserting chunks into db;;; ====\")\n",
    "    collection.upsert(\n",
    "        ids=[doc[\"id\"]], documents=[doc[\"text\"]], embeddings=[doc[\"embedding\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "{'id' : 'doc1', 'text' : 'Hello world'},\n",
    "{'id' : 'doc2', 'text' : 'How are you doing today'},\n",
    "{'id' : 'doc3', 'text' : 'Goodbye, See you later'},\n",
    "{'id' : 'doc4', 'text' : 'Welcome again!'},\n",
    "]\n",
    "\n",
    "# Adding the documents into the collection\n",
    "\n",
    "for doc in documents:\n",
    "    collection.upsert(ids = doc['id'], documents = doc['text'])\n",
    "\n",
    "query = \"Hello\"\n",
    "results = collection.query(query_texts = [query], n_results=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
